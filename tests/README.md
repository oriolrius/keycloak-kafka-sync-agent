# Testing Guide: Keycloak Password Sync SPI for Kafka SCRAM

Complete testing documentation covering infrastructure setup, E2E tests, and validation procedures.

---

## Table of Contents

- [Overview](#overview)
- [Directory Structure](#directory-structure)
- [Quick Start](#quick-start)
- [Testing Infrastructure](#testing-infrastructure)
- [E2E Tests](#e2e-tests)
- [Test Validation](#test-validation)
- [Troubleshooting](#troubleshooting)

---

## Overview

This directory contains all testing infrastructure and end-to-end tests for the Keycloak Password Sync SPI:

### What We Test

1. **Infrastructure**: Docker Compose stack with KMS, Keycloak, and Kafka
2. **SPI Functionality**: Password synchronization from Keycloak to Kafka SCRAM credentials
3. **SCRAM Authentication**: Both SCRAM-SHA-256 and SCRAM-SHA-512 mechanisms
4. **End-to-End Flow**: Complete validation from user password change to Kafka client authentication

### Test Coverage

- âœ… SCRAM-SHA-256 credential generation and synchronization
- âœ… SCRAM-SHA-512 credential generation and synchronization
- âœ… Kafka producer authentication with synced credentials
- âœ… Kafka consumer authentication with synced credentials
- âœ… Message production and consumption with authenticated clients
- âœ… SSL/TLS encrypted communication
- âœ… Certificate management with Cosmian KMS

---

## Directory Structure

```
tests/
â”œâ”€â”€ README.md                          # This file
â”‚
â”œâ”€â”€ infrastructure/                     # Docker Compose testing stack
â”‚   â”œâ”€â”€ docker-compose.yml             # Service definitions
â”‚   â”œâ”€â”€ Makefile                       # Infrastructure commands
â”‚   â”œâ”€â”€ README.md                      # Infrastructure details
â”‚   â”œâ”€â”€ env.example                    # Configuration docs
â”‚   â”œâ”€â”€ data/                          # Persistent data (gitignored)
â”‚   â”‚   â”œâ”€â”€ kms/                       # KMS database
â”‚   â”‚   â”œâ”€â”€ keycloak/                  # Keycloak SQLite DB
â”‚   â”‚   â””â”€â”€ kafka/                     # Kafka logs and state
â”‚   â”œâ”€â”€ certs/                         # SSL certificates
â”‚   â”œâ”€â”€ kafka-config/                  # Kafka configuration
â”‚   â”‚   â”œâ”€â”€ kafka-entrypoint.sh        # Custom entrypoint
â”‚   â”‚   â”œâ”€â”€ kafka_server_jaas.conf     # SASL configuration
â”‚   â”‚   â””â”€â”€ server.properties          # Kafka properties
â”‚   â”œâ”€â”€ scripts/                       # Helper scripts
â”‚   â”‚   â”œâ”€â”€ configure-keycloak-realm.sh
â”‚   â”‚   â””â”€â”€ enable-event-listener.sh
â”‚   â””â”€â”€ dockerfiles/                   # Custom Dockerfiles
â”‚
â””â”€â”€ e2e/                               # End-to-end tests
    â”œâ”€â”€ README.md                      # E2E test details
    â”œâ”€â”€ scram-sync-e2e.test.js         # Main E2E test
    â”œâ”€â”€ test-both-mechanisms.sh        # Test orchestration
    â”œâ”€â”€ test-log-parsing.js            # Consumer readiness demo
    â”œâ”€â”€ package.json                   # NPM dependencies
    â””â”€â”€ package-lock.json
```

---

## Quick Start

### 1. Start Testing Infrastructure

```bash
cd tests/infrastructure
make start
```

This starts:
- **KMS** (Certificate Authority) on port `57001`
- **Keycloak** (with SPI) on port `57003` (HTTPS)
- **Kafka** on port `57005` (SSL)

### 2. Run E2E Tests

```bash
cd tests/e2e
./test-both-mechanisms.sh
```

This automatically:
1. Builds the Keycloak SPI
2. Tests SCRAM-SHA-256 mechanism
3. Cleans up and restarts services
4. Tests SCRAM-SHA-512 mechanism
5. Reports results for both

### 3. Expected Output

```
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
   SCENARIO 1: Testing SCRAM-SHA-256
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
âœ… SPI built successfully
âœ… Keycloak is ready
âœ… Kafka is ready
âœ… Event listener enabled
âœ… User created in Keycloak
âœ… Producer connected with SCRAM-SHA-256
âœ… Consumer connected with SCRAM-SHA-256
âœ… Message published and received

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
   SCENARIO 2: Testing SCRAM-SHA-512
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
âœ… SPI built successfully
âœ… Keycloak is ready
âœ… Kafka is ready
âœ… Event listener enabled
âœ… User created with SCRAM-SHA-512
âœ… Producer connected with SCRAM-SHA-512
âœ… Consumer connected with SCRAM-SHA-512
âœ… Message published and received

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
   ğŸ‰ ALL TESTS PASSED
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

---

## Testing Infrastructure

### Services

The testing infrastructure provides a complete stack for local development and testing:

| Service | Purpose | Ports | Credentials |
|---------|---------|-------|-------------|
| **KMS** | Certificate Authority (Cosmian) | 57001 | - |
| **Keycloak** | Identity Provider with SPI | 57003 (HTTPS) | admin / The2password. |
| **Kafka** | Message Broker (KRaft mode) | 57005 (SSL) | admin / The2password. |

### Network

All services run on the `keycloak-kafka-backbone` Docker network.

### SSL/TLS Setup

Certificates are automatically generated using Cosmian KMS:

- **Root CA**: `tests/infrastructure/certs/ca-root.pem`
- **Keycloak**: `tests/infrastructure/certs/keycloak_server.pem/p12`
- **Kafka**: `tests/infrastructure/certs/kafka_broker.pem/p12`
- **Java Keystores**: `tests/infrastructure/certs/*.jks` (for Kafka)

### Data Persistence

Data is stored in `tests/infrastructure/data/` using bind mounts:
- KMS database and keys
- Keycloak SQLite database
- Kafka logs and state

### Infrastructure Commands

```bash
cd tests/infrastructure

# Setup
make start        # Start all services
make kms-only     # Start only KMS
make certs        # Generate certificates

# Control
make stop         # Stop services
make down         # Stop and remove containers
make restart      # Restart services
make clean        # Full cleanup (interactive)

# Monitoring
make status       # Service status
make health       # Health check
make logs         # All logs
make logs-kafka   # Kafka logs only
make logs-keycloak # Keycloak logs only

# Kafka
make test-topic   # Create test topic
make list-topics  # List topics
make producer     # Console producer
make consumer     # Console consumer

# Utilities
make shell-kafka  # Shell into Kafka
make shell-keycloak # Shell into Keycloak
make inspect-certs # View certificate details
make config       # Show current configuration
```

### Prerequisites

Required tools:
```bash
ckms          # Cosmian KMS CLI (in ../contrib/ckms)
keytool       # Java keystore tool
openssl       # SSL/TLS toolkit
docker        # Container runtime
make          # Build automation
```

To use `ckms` globally:
```bash
mkdir -p ~/.local/bin
ln -sf $(pwd)/../contrib/ckms ~/.local/bin/ckms
export PATH="$HOME/.local/bin:$PATH"
```

---

## E2E Tests

### Test Architecture

The E2E tests validate the complete password synchronization flow:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  1. CREATE USER â”‚  Create user in Keycloak with password
â”‚   IN KEYCLOAK   â”‚  Realm: master
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜  Username: test-user-<timestamp>
         â”‚           Password: TestPassword123!
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  2. SPI SYNCS   â”‚  Password event triggers SPI
â”‚  TO KAFKA       â”‚  - Generates SCRAM credentials
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜  - Upserts to Kafka via AdminClient
         â”‚           - Wait 2 seconds for sync
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  3. PRODUCER    â”‚  Authenticate to Kafka with SCRAM
â”‚  AUTHENTICATES  â”‚  - Connect with SSL/TLS
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜  - Authenticate with SCRAM-SHA-256/512
         â”‚           - Create topic with leader election
         â”‚           - Publish message
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  4. CONSUMER    â”‚  ğŸ¯ CRITICAL VALIDATION ğŸ¯
â”‚  AUTHENTICATES  â”‚  - Connect with SSL/TLS
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜  - Authenticate with SCRAM-SHA-256/512
         â”‚           - Wait for consumer group ready
         â”‚           - Consume message
         â–¼
         âœ…
    COMPLETE!
```

### What the Tests Validate

#### âœ… Password Synchronization
- User password is intercepted by SPI before Keycloak hashing
- SCRAM credentials are generated (RFC 5802 compliant)
- Credentials are synced to Kafka via AdminClient API

#### âœ… SCRAM Authentication
- **Producer** authenticates with synced credentials
- **Consumer** authenticates with synced credentials
- Both SCRAM-SHA-256 and SCRAM-SHA-512 work

#### âœ… End-to-End Functionality
- Topic creation and leader election
- Message production
- Consumer group coordination
- Message consumption

### Running Individual Tests

**Test specific mechanism:**
```bash
cd tests/e2e

# SCRAM-SHA-256 only
export TEST_SCRAM_MECHANISM=256
node scram-sync-e2e.test.js

# SCRAM-SHA-512 only
export TEST_SCRAM_MECHANISM=512
node scram-sync-e2e.test.js
```

**Note**: Services must already be running with the correct mechanism configured.

### Log Parsing for Consumer Readiness

The tests use a custom log parser to detect when the Kafka consumer group is ready:

```javascript
const { logCreator, groupReadyPromise } = createConsumerGroupReadyWatcher();

// Wait for consumer group to initialize
await groupReadyPromise;
console.log(`âœ… Consumer group ready`);
```

This eliminates arbitrary timeouts and provides precise, event-driven synchronization.

**Demo the log parsing:**
```bash
cd tests/e2e
node test-log-parsing.js
```

### About Transient Errors

âš ï¸ **Expected ERROR Logs During Consumer Startup**

You will see ERROR logs like:
```json
{"level":"ERROR","message":"The group coordinator is not available"}
{"level":"ERROR","message":"The coordinator is loading and hence can't process requests"}
```

**This is COMPLETELY NORMAL!**

Why:
1. Consumer group initialization takes 1-3 seconds
2. Coordinator must be elected and load metadata
3. KafkaJS has built-in retry logic (300ms initial, 8 retries)
4. Tests wait for the exact moment consumer is ready

Tests still pass successfully because the retry logic handles these transient errors.

---

## Test Validation

### What This Proves

#### âœ… RFC 5802 Compliance
- SCRAM credential generation follows RFC 5802
- PBKDF2 parameters are correct
- Base64 encoding is proper

#### âœ… Kafka Integration
- AdminClient API usage is correct
- Credentials are stored in Kafka's internal store
- Both SHA-256 and SHA-512 mechanisms work

#### âœ… Password Flow
- Passwords are intercepted before Keycloak hashing
- ThreadLocal correlation works correctly
- No password leakage or persistence

#### âœ… Client Authentication (Critical!)
- **Kafka producers authenticate with synced credentials**
- **Kafka consumers authenticate with synced credentials**
- **SCRAM handshake succeeds**
- **SSL/TLS + SCRAM work together**
- **Full message flow works**

### Evidence Points

Each test step provides specific evidence:

**STEP 1: User Created**
- HTTP 201 Created from Keycloak API
- Password set successfully (HTTP 204)

**STEP 2: Kafka Cluster Ready**
- `describeCluster()` returns broker info
- Topic created with leader elected

**STEP 3: Producer Authentication**
- Producer connects without errors
- Message published successfully

**STEP 4: Consumer Authentication (CRITICAL!)**
- Consumer connects without errors
- Consumer group joins successfully
- Message consumed successfully
- All messages match

---

## Troubleshooting

### Services Not Starting

**KMS not starting:**
```bash
cd tests/infrastructure
docker logs kms
# Check if port 57001 is available
```

**Keycloak not starting:**
```bash
cd tests/infrastructure
docker logs keycloak
# Verify KMS is healthy first
make health
```

**Kafka not connecting:**
```bash
cd tests/infrastructure
docker logs kafka
# Verify certificates exist
ls -la certs/*.jks
```

### Tests Failing

**"SASL authentication failed":**
- SPI hasn't created credentials yet
- Check Keycloak logs: `docker logs keycloak`
- Verify event listener enabled: Check test output
- Increase sync wait time in test (currently 2 seconds)

**"Connection refused":**
- Services not running
- Check: `docker compose ps` from `tests/infrastructure/`
- Check ports: `netstat -tuln | grep -E '57001|57003|57005'`

**"Topic metadata not available":**
- Topic leadership not ready
- Test already handles this with `ensureTopicWithLeaders()`
- If persists, increase timeout (line 202 in scram-sync-e2e.test.js)

**"No message received within 15 seconds":**
- Producer didn't publish or consumer didn't subscribe
- Check producer logs - was message published?
- Check consumer logs - did it subscribe?
- Verify topic name matches

**Transient errors persist:**
- Kafka coordinator genuinely unavailable
- Check: `docker logs kafka`
- Restart: `make restart` from `tests/infrastructure/`
- Clean slate: `make clean && make start`

### Certificate Errors

```bash
cd tests/infrastructure

# Regenerate certificates
make clean  # Answer 'y' when prompted
make start
```

### Network Issues

```bash
# Check network exists
docker network ls | grep keycloak-kafka-backbone

# Recreate if needed
docker network rm keycloak-kafka-backbone
cd tests/infrastructure
docker compose up -d
```

### Clean Slate

```bash
cd tests/infrastructure
make clean  # Removes everything
make start  # Fresh start
```

---

## Configuration

### Environment Variables

The infrastructure uses environment variables with defaults:

```bash
# Kafka SCRAM mechanism (256 or 512)
KAFKA_SCRAM_MECHANISM=256

# Service URLs
KEYCLOAK_URL=https://localhost:57003
KAFKA_BROKERS=localhost:57005

# Credentials
KEYCLOAK_ADMIN=admin
KEYCLOAK_ADMIN_PASSWORD=The2password.
```

To override defaults, create `tests/infrastructure/.env`:
```bash
cd tests/infrastructure
cp env.example .env
# Edit .env with your values
```

See `tests/infrastructure/env.example` for all available options.

### Makefile Variables

Override infrastructure settings:
```bash
cd tests/infrastructure

# View current configuration
make config

# Override domain
make start DOMAIN=mycompany.local

# Override specific variables
make start CERT_PASSWORD=MySecurePass
```

---

## Important Notes

âš ï¸ **For Testing Only**

- Password `The2password.` is for testing only
- SQLite is used for simplicity (use PostgreSQL in production)
- Self-signed certificates (replace with proper CA in production)
- All ports in 57000 range to avoid conflicts

âš ï¸ **Security in Production**

For production deployments:
1. Use TLS for all Kafka connections
2. Secure credentials with environment secrets management
3. Enable audit logging for password sync events
4. Implement network isolation between Keycloak and Kafka
5. Keep Keycloak and Kafka updated

---

## Additional Resources

- [KafkaJS Documentation](https://kafka.js.org/)
- [Kafka SCRAM Authentication](https://kafka.apache.org/documentation/#security_sasl_scram)
- [RFC 5802 - SCRAM](https://tools.ietf.org/html/rfc5802)
- [Keycloak Event SPI](https://www.keycloak.org/docs/latest/server_development/#_events)
- [Cosmian KMS](https://github.com/Cosmian/kms)

---

## Summary

This testing suite provides **complete validation** of the Keycloak Password Sync SPI:

1. âœ… Infrastructure setup with Docker Compose
2. âœ… SSL/TLS certificate generation with KMS
3. âœ… SCRAM credential generation and synchronization
4. âœ… End-to-end authentication flow validation
5. âœ… Both SCRAM-SHA-256 and SCRAM-SHA-512 tested

**The tests prove that passwords synced from Keycloak can be used to successfully authenticate Kafka clients with SCRAM.**

For detailed infrastructure documentation, see `tests/infrastructure/README.md`.
For detailed E2E test documentation, see `tests/e2e/README.md`.
